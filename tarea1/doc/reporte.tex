\documentclass {article}

\usepackage[spanish]{babel}
\usepackage [T1]{fontenc}
\usepackage [utf8]{inputenc}
\usepackage {graphicx}
\usepackage{subcaption}
\usepackage{listings}
\usepackage{multirow}

\begin {document}

\title{Tarea1: Simulación de cache}
\author{Daniel García Vaglio}
\maketitle
%\begin{abstract}

%\end{abstract}


\section{Protocolo MESI}
El protocolo MESI toma su nombre de las banderas que se utilizan para lograr la concurrencia, que
indican el estado del bloque. Estas banderas son: ``Invalid'', ``Exclusive'', ``Shared'' y
``Modified''(están presentes en cada bloque). \textit{Invalid} implica que el bloque se encuentra inválido, entonces no se pueden hacer
lecturas del dato. \textit{Exclusive} se refiere a que el bloque se encuentra válido en esta unidad de cache,
pero no se encuentra válido en ningún ninguna otra. Luego \textit{Shared} se refiere a que el bloque se
encuentra válido en la presente unidad de cache, pero también se encuentra válido en alguna otra
unidad de caché (al menos una). Finalmente \textit{Modified} se utiliza para señalar que el bloque se
encuentra válido en el presente cache, pero que a diferencia de \textit{Exclusive} y \textit{shared}, este dato no
coincide con el dato en memoria RAM.

Este protocolo es utilizado para la concurrencia de los datos en cache, ya que con el sistema de
banderas evita que se lea un dato que no es válido (que haya sido escrito por otro Core, y se lee el
dato sin mutar), y también garantiza que los datos mutados en cache, se guardan en la memoria RAM
adecuadamente.

En cuanto a la implementación, se deben considerar las instrucciones que el cache puede recibir,
estas vienen de dos partes, del core y del bus. El bus es un módulo que está conectado a todos los
caches del mismo nivel y se encarga de mantener los datos concurrentes entre ellos. En primer lugar
se tiene que tomar en cuenta que el cache recibe instrucciones desde el core, en el que trata de
accesar a un bloque específico. Dependiendo de la bandera en el bloque el bus debe ejecutar
instrucciones específicas, a continuación se muestra un resumen:
\begin{center}
 \begin{tabular}{|c | c | l |} 
 \hline
 Instrucción & Bandera & Acción \\ 
 \hline
   \multirow{10}{*}{Core Read}  & \textit{Modified} & \textbullet Estado permanece igual \\
                               &          & \textbullet Hit \\ \cline{2-3}
   
             & \textit{Exclusive} & \textbullet Estado permanece igual \\
             &           & \textbullet Hit \\ \cline{2-3}
 
             & \textit{Shared} & \textbullet Estado permanece igual  \\
             &        & \textbullet Hit \\ \cline{2-3}
 
             & \textit{Invalid} & \textbullet Verificar si el dato está en otro cache\\
             &         & \textbullet Se hace fetch al nivel siguiente de cache\\
             &         & \textbullet Si está pasar a \textit{Shared}, si no pasar a \textit{Exclusive} \\ \cline{2-3}
 \hline
   \multirow{9}{*}{Core Write} & \textit{Modified} & \textbullet Estado permanece igual \\
             & & \textbullet Write Hit\\ \cline{2-3}
             & \textit{Exclusive} & \textbullet Estado cambia a \textit{Modified} \\
             & & \textbullet Write Hit\\ \cline{2-3}
             & \textit{Shared} & \textbullet Estado pasa a \textit{Modified} \\
             & & \textbullet Se invalidan copias del bloque en otros caches.\\
             & & \textbullet Write Hit\\ \cline{2-3}
             & \textit{Invalid}  & \textbullet Estado pasa a \textit{Modified}\\
   & & \textbullet Write Miss\\ \cline{2-3}
 \hline
 \end{tabular}
\end{center}



\section{Implementación}
Se toma la decisión de implementarlo en Python 2.7 que está disponible en la última versión de
ubuntu LTS. El script principal se llama ``main.py'' y tiene varios modos de funcionamiento que se
configuran con argumentos a la hora de ejecutarlo. Para una descripción breve de las funcionalidades
del script principal y su uso, se puede ejecutar ``python2 main.py --help''. Se puede cambiar los
archivos que se utilizan para las instrucciones de los cores, se puede activar la bandera de
``debug'' para recibir más información de la simulación, también al indicar un ``output\_file'' esta
información se guarda en un archivo en lugar de imprimirse en terminal, para permitir que se revise
después. Además se puede editar la razón de instrucciones que ejecuta cada core, por defecto el core
1 ejecuta 3 mientras el core 2 ejecuta 1, como se indica en las instrucciones de la tarea, pero estos parámetros
se pueden edita. También se ofrece la opción de ejecutar una simulación o varias, de manera que se puedan
hacer varias pruebas separadas con una sola ejecución del script.

Otra funcionalidad es la de
generar archivos de instrucciones aleatorias. De esta manera se crean archivos de texto con el
formato necesario para ser leído para las simulaciones. Estas instrucciones no son completamente
aleatorias, sino que se organizan en ``mega clusters'' y ``clusters'' de instrucciones. Los ``mega
clusters'' son grandes secuencias de direcciones aleatorias que pertenecen a un rango amplio para modelar el
comportamiento de un programa. Por otra parte los clusters son secuencias cortas de instrucciones
con direcciones cercanas, que modelan el comportamiento de funciones dentro de un programa. Los
archivos generados se pueden utilizar por el script principal para luego hacer simulaciones, y
tienen el objetivo de probar varios casos de entradas posibles, y también para ser utilizados en el
análisis de misses y hits del sistema de caches. para cada caso se selecciona de forma aleatoria si
se hace una lectura o una escritura. 

\subsection{Script principal de simulación}
Como se indicó con anterioridad el script principal de simulación puede hacer una o varias
simulaciones. El proceso es muy parecido, solo que cuando hay varias simulaciones los archivos de
entrada con las instrucciones para los cores se dividen en partes iguales y se pasan a cada
simulación por aparte. En adelante ambos casos son equivalentes.

Primero se realiza la lectura de los archivos, y se traducen del texto plano a una estructura de
datos más fácil de manejar para Python. Cada línea del archivo se convierte en las entradas de una
lista que contiene la dirección y si se trata de una lectura o una escritura. Además las
direcciones se guardan como strings que representan al número en binario, y se le agregan tantos
ceros al frente como sean necesarios para que tengan una tamaño mínimo específico. Esto se realiza
para facilitar el manejo de los datos en las siguientes etapas de la simulación.


Para poder emular la concurrencia que sucede en el sistema real se utilizan distintos procesos que se
ejecutan en paralelo. Python ofrece una interfaz de mensajes para poder intercomunicar procesos, por
lo que se utilizan a modo de puertos de comunicación. De esta manera, por ejemplo los datos que se
piden de memoria llegan por un puerto, y las instrucciones que se envían a cache van en otro puerto
distinto. Para una simulación se levantan 5 procesos, uno es el proceso de los cores estos se
encargan de leer la lista de instrucciones descrita anteriormente y de comunicarse con los caches
L1 de manera apropiada. Luego está el proceso de cache L1, este se encarga de la simulación de
ambos caches L1, y es donde se implementa el protocolo MESI. Otro proceso es el del cache L2, en este
caso se implementa el cache de segundo nivel. Luego está el proceso de la memoria, este se encarga
de simular el comportamiento de la memoria RAM en este sistema. Finalmente se tiene un quinto
proceso que se encarga de recibir los datos de todos los anteriores y organizarlos para hacer
impresiones en terminal con formato entendible y se encarga de generar los archivos de salida en caso
que el usuario así lo solicite. Es importante destacar que este quinto proceso no es parte de la
simulación de hardware, sino que es un proceso utilitario que permite la verificación del sistema
con mayor facilidad.

EN el script principal se crean todos los puertos de comunicación necesarios entre procesos. Los
puertos de comandos desde los niveles superiores hacia los niveles inferiores, y los puertos de
transferencia de datos se crean por aparte. Todos se organizan en un diccionario. Estos puertos y
otros parámetros utilitarios son los que se utilizan para inicializar los 5 procesos descritos.

Una simulación termina cuando ambos cores han terminado de ejecutar todas las instrucciones, en este
caso el proceso de los cores genera una señal para indicarle al resto que deben terminar. El proceso
de los cores termina automáticamente. Es en este momento que se hace el manejo de los estados
finales de los caches.

\subsection{Cores}

El proceso de los cores recibe como entrada ambas listas de instrucciones. Luego itera sobre ellas
sucesivamente hasta que ambas se hayan completado. En cada iteración uno de los cores envía las
instrucciones a su respectivo cache L1. En caso de ser necesario genera datos aleatorios para
enviarlos al cache, o espera a recibir los datos del cache. 


\subsection{Cache L1}
El módulo del cache L1 que crea dos objeto tipo cacheL2w con los tamaños requeridos y los puertos de
salida y entrada. Luego ejecuta los métodos que se encargan de escuchar las entradas y generar las
salidas. Este método es un loop que se espera a recibir una instrucción del nivel superior, esta
llega por el puerto de instrucciones.

Los datos en cache se guardan en un diccionario, donde el identificador es un string con el index en
binario, y este se asocia a un objeto tipo Block\_pair. Este objeto simula el comportamiento LRU del
set (El cache es 2 way associative LRU). Cada Block\_pair contiene dos objetos tipo Block\_MESI que
guardan los datos asociados al bloque y el tag, además se encargan de la transición de estados. 

El proceso de ejecución de una instrucción se divide en dos partes generales. La primera parte se
encarga del manejo de misses, y la segunda se encarga de la ejecución de la instrucción como
tal. Entonces al recibir una instrucción, el cache toma las instrucciones y las divide en el tag, el
index y el offset. Para esta parte es muy conveniente que se tomen las direcciones en formato
binario, para facilitar la división de la instrucción. Luego se busca en el diccionario el bloque
que contenga el tag requerido. En caso que no se encuentre se activa la bandera de miss y se ejecuta
la función para manejo de misses.

En la función de manejo de misses, primero se revisa el estado del bloque actual, encaso de estar en
\textit{Modified} se hace un flush del bloque para mantener la coherencia entre el cacheL1 y el cache
L2. Luego se busca el tag en el otro cache L1, para esto cada cache tiene un puntero al otro. En
caso de encontrarse el tag, se trae el dato. Si el dato en el otro cache se encuentra en \textit{Modified} se
hace flush, para garantizar coherencia y finalmente ambos bloques transicionan a \textit{Shared}. Si el tag
no se encuentra en el otro cache L1, entonces se le envía una solicitud al cache L2 por el
bloque, en este caso el bloque termina en \textit{Exclusive}. Nótese que todos los bloques inválidos levantan
la bandera de miss. 

Una vez que se ha ejecutado la función de manejo de misses se ha asegurado que se tiene coherencia
entre caches y con el cache L2. Además se garantiza que el bloque que se necesita se encuentra en el
cache L1 apropiado. Luego se ejecuta la instrucción del core. En caso de ser una lectura se pasa el
byte al cache por medio de un puerto. En caso de ser de escritura se toma el dato del puerto y se
escribe en el bloque. Este pasa a ser \textit{Modified}, y en caso de estar en \textit{Shared} entonces se invalida
la copia en el otro cache. Se debe notar que durante la ejecución de la instrucción el bloque puede
cambiar varias veces de estado, esto porque el manejo de misses y la ejecución de instrucciones del
core se hacen por separado.

\subsubsection{Block pair}

Como este es un cache two way set associative, entonces en cada entrada del diccionario de indexes en
el cache se encuentran dos bloques. Cada vez que el core accesa datos de alguno de ellos (ni importa
si es escritura o lectura), se le suma un contador al bloque correspondiente. Cuando los datos se
accesan por parte de otro cache, este contador no se incrementa. Cuando se trae en bloque nuevo al
cache, este inicia con el contador en 0. Estos contadores se utilizan para implementar LRU. Entonces
en un miss cuando se solicita el bloque LRU para ser sustituido, se retorna el bloque con el
contador menor valor.

\subsubsection{Block MESI}

Este es un objeto donde se implementa el protocolo MESI, en el sentido que se encarga de identificar
las instrucciones que se le solicitan al bloque y hacer la transición apropiada de estados.
%
%FIXME: EXPANDIR SOBRE IMPLEMENTACION. 
%

\subsection{CacheL2}

El protocolo MESI fue creado par asegurar la coherencia de datos entre \textbf{2 o más} caches del
mismo nivel. Como este cache es único, entonces no tiene sentido utilizar MESI. en su lugar se
utilizan tres banderas que indican si el dato es inválido, es válido (coherente con memoria
principal), o si está modificado (válido, pero distinto al dato en memoria). Este cache al igual que
el anterior tiene una función que se ejecuta indefinidamente y está escuchando el puerto de comandos
para saber cuando alguno de los cache L1 le hace una solicitud de un bloque o hace un flush de un
bloque.

Este cache se organiza como un diccionario, donde el identificador es un string con los indexes en
representación binaria y se asocia a un objeto tipo bloque. Este objeto tipo bloque almacena los
datos y el tag correspondiente. Sin embargo como la transición de estados es tan simple, esta se
maneja por parte del cache, y no por parte del bloque.

Cuando se recibe una instrucción del cache L1, primero se realiza la división de la dirección en
tag, index y offset. Se debe notar que esta división es distinta a la que se tiene en cache
L1. Además la parte del offset son solamente ceros, porque los bloques son del mismo tamaño. La
ejecución de la instrucción también se divide en dos partes: el manejo de misses, y la ejecución de
la instrucción como tal. En primer lugar se busca el tag correspondiente dentro del cache, si se
encuentra se procede a ejecutar la instrucción, pero en caso contrario se ejecuta la función de
manejo de misses.

En la función de manejo de misses primero se hace flush del bloque actual a la memoria principal,si
este se encuentra modificado, y
luego se hace la solicitud a la memoria del bloque que necesita cache L1. Este dato se trae y se
guarda en el cache L2, se asigna bandera de válido.

En al parte de la ejecución de la instrucción recibida por parte del cache L1, en caso de ser de
lectura se envían los datos del bloque, en caso de ser escritura, se toman los datos y se el asigna
la bandera de modificado.

\section{Memoria Principal}

La memoria principal es un proceso que se encarga de simular el comportamiento de la memoria RAM en
este sistema. Al igual que los caches se mantiene escuchando el puerto de comandos en espera que el
nivel superior le haga una solicitud. Esta memoria tiene un diccionario, donde guarda la dirección
asociada y la socia al dato (lista de 32 bytes).  Estos se generan en cada solicitud del cacheL2. En
caso de haber una lectura, la memoria primero busca en el diccionario si ese dato ya está
disponible y lo envía, si no lo está entonces crea uno aleatorio, lo guarda y lo envía. Si el
comando es de escritura, busca si el dato ya está disponible y los modifica, si no, entonces crea
una entrada nueva, y lo guarda.

\section{Consideraciones sobre comandos}
Se ha explicado que los niveles superiores envían comandos a los niveles inferiores. El ejemplo más
claro es la relación entre el core y el cache L1. Este comando es una lista de dos elementos, el
primero indica la dirección, y el segundo indica si es escritura o lectura. Entonces es parecido a
este ejemplo: [``0101...101'', ``{S}'']. En caso que haya un miss, y se deba hacer un flush, entonces el
cache L1 va a enviarle al cache L2 la siguiente instrucci\'o n: [``1001...000'', ``{S}''], para escribir
el bloque a sustituir en L2. Y luego va a enviar [``0101...000'', ``{L}''], para leer el bloque
correspondiente. Note que internamente todo se trabaja en binario, no hexadecimal, además escritura
o lectura se indica encerrado en llaves. Por otra parte el offset que se trabaja del cacheL2 para
abajo es siempre cero, porque estas transferencias son de bloques enteros. Las transferencias entre
los cores y sus caches L1 son únicamente de bytes (para esta implementación las palabras son de un byte). 


\section{Funcionamiento y Pruebas}

\subsection{Miss rate y Hit rate}

\section{Beneficios de MESI}

\section{Deficiencias de MESI}


\end{document}
